{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4edff8",
   "metadata": {},
   "source": [
    "## Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee215a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import Random\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 5\n",
    "random_gen = Random(x = SEED)\n",
    "def generate_pts(N = 1000):\n",
    "    return(\n",
    "        [random_gen.uniform(a = 0, b = 1) for _ in range(N)],\n",
    "        [random_gen.uniform(a = 0, b = 1) for _ in range(N)]\n",
    "    )\n",
    "data_x, data_y = generate_pts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f2cc8d",
   "metadata": {},
   "source": [
    "## Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b26f030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def loss(x_p, y_p):\n",
    "    return (1/len(data_x))*sum(\n",
    "        [sqrt((x_i - x_p)**2+(y_i - y_p)**2) for x_i, y_i in zip(data_x, data_y)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0934daa",
   "metadata": {},
   "source": [
    "## Gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f5854e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is the function carrying out the gradient descent updating the xp and yp values\n",
    "# It takes the initial values for x_p and y_p, the H used to calculate the derivative, the DELTA which is the STEP or\n",
    "# the learning rate used to update x_p and y_p and EPOCHS (no of iterations)\n",
    "# It returns the final values for x_p and y_p and two lists we used to keep trach of the different x_p and y_p values\n",
    "# with each epoch\n",
    "\n",
    "def optimize_return_parameters_list(x_p_init, y_p_init, H, DELTA, EPOCHS):\n",
    "    x_p, y_p = x_p_init, y_p_init\n",
    "    x_p_list =[]\n",
    "    y_p_list =[]\n",
    "    for _ in range(EPOCHS):\n",
    "        x_p_list.append(x_p)\n",
    "        y_p_list.append(y_p)\n",
    "        dloss_dx = (loss(x_p+H, y_p) - loss(x_p, y_p))/H\n",
    "        dloss_dy = (loss(x_p, y_p+H) - loss(x_p, y_p))/H\n",
    "        x_p-= dloss_dx * DELTA   \n",
    "        y_p-= dloss_dy * DELTA\n",
    "    return x_p, y_p, x_p_list, y_p_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478504e",
   "metadata": {},
   "source": [
    "## Dr.Meena's Original trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea87f005",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_p_final, y_p_final, x_p_list, y_p_list = optimize_return_parameters_list(5, 5, 0.001, 0.01, 3000)\n",
    "\n",
    "print(f\"The final xp value: {x_p_final} and the final yp value: {y_p_final}\")\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "\n",
    "xp_ax = fig.add_subplot(1, 2, 1)\n",
    "yp_ax = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "xp_ax.plot(x_p_list)\n",
    "yp_ax.plot(y_p_list)\n",
    "\n",
    "xp_ax.set_title('Xp values with iterations')\n",
    "yp_ax.set_title('Yp values with iterations')\n",
    "\n",
    "#since our value is decimal I wanted to see more grading on the y axis using set_ticks\n",
    "xp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "xp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "yp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "yp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97734816",
   "metadata": {},
   "source": [
    "## Trial 1\n",
    "**Negative initial xp and yp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c06ca37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_p_final, y_p_final, x_p_list, y_p_list = optimize_return_parameters_list(-5, -5, 0.001, 0.01, 3000)\n",
    "\n",
    "print(f\"The final xp value: {x_p_final} and the final yp value: {y_p_final}\")\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "\n",
    "xp_ax = fig.add_subplot(1, 2, 1)\n",
    "yp_ax = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "xp_ax.plot(x_p_list)\n",
    "yp_ax.plot(y_p_list)\n",
    "xp_ax.set_title('Xp values with iterations')\n",
    "yp_ax.set_title('Yp values with iterations')\n",
    "\n",
    "# xp_ax.yaxis.set_ticks([0.2*i for i in range(-25, 6)])\n",
    "# xp_ax.set_ylim(bottom = -5, top = 1)\n",
    "\n",
    "# yp_ax.yaxis.set_ticks([0.2*i for i in range(-25, 6)])\n",
    "# yp_ax.set_ylim(bottom = -5, top = 1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8403f88",
   "metadata": {},
   "source": [
    "### Comment\n",
    "Since the initial value was negative unlike the previous example thee xp and yp values went up instead of decreasing, it did converge at the end to the optimum value, maybe taking a little longer than the previous example because it had a larger gap from the optimum value than the original example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecfc3c9",
   "metadata": {},
   "source": [
    "## Trial 2\n",
    "**xp and yp are close to 0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bccf755c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_p_final, y_p_final, x_p_list, y_p_list = optimize_return_parameters_list(0.7, 0.7, 0.001, 0.01, 3000)\n",
    "\n",
    "print(f\"The final xp value: {x_p_final} and the final yp value: {y_p_final}\")\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "xp_ax = fig.add_subplot(1, 2, 1)\n",
    "yp_ax = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "xp_ax.plot(x_p_list)\n",
    "yp_ax.plot(y_p_list)\n",
    "xp_ax.set_title('Xp values with iterations')\n",
    "yp_ax.set_title('Yp values with iterations')\n",
    "\n",
    "xp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "xp_ax.xaxis.set_ticks([200*i for i in range(16)])\n",
    "xp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "yp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "yp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44632031",
   "metadata": {},
   "source": [
    "### Comment\n",
    "By setting the xp and yp to a number close to the optimum solution, convergence did happen much faster than in the original trial. It almost settled after 200 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ef6df",
   "metadata": {},
   "source": [
    "## Trial 3\n",
    "**Trying a bigger H**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7909aa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_p_final, y_p_final, x_p_list, y_p_list = optimize_return_parameters_list(5, 5, 0.1, 0.01, 3000)\n",
    "\n",
    "print(f\"The final xp value: {x_p_final} and the final yp value: {y_p_final}\")\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "xp_ax = fig.add_subplot(1, 2, 1)\n",
    "yp_ax = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "xp_ax.plot(x_p_list)\n",
    "yp_ax.plot(y_p_list)\n",
    "\n",
    "xp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "xp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "yp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "yp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "xp_ax.set_title('Xp values with iterations')\n",
    "yp_ax.set_title('Yp values with iterations')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7ad59",
   "metadata": {},
   "source": [
    "### Comment\n",
    "Due to the large H as compared to the original in the derivative definition where h approaches zero, the calculation of the derivative is way off and the final values printed above are pretty far from the optimum solution. **The error is large**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11affb71",
   "metadata": {},
   "source": [
    "## Trial 4\n",
    "**Trying a bigger DELTA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca53995",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_p_final, y_p_final, x_p_list, y_p_list = optimize_return_parameters_list(5, 5, 0.001, 1.5, 3000)\n",
    "\n",
    "print(f\"The final xp value: {x_p_final} and the final yp value: {y_p_final}\")\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "xp_ax = fig.add_subplot(1, 2, 1)\n",
    "yp_ax = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "xp_ax.scatter([i for i in range(3000)], x_p_list, s=2)\n",
    "yp_ax.scatter([i for i in range(3000)], y_p_list, s=2)\n",
    "xp_ax.set_title('Xp values with iterations')\n",
    "yp_ax.set_title('Yp values with iterations')\n",
    "\n",
    "xp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "xp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "yp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "yp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2129e84",
   "metadata": {},
   "source": [
    "### Comment\n",
    "Using a higher learning rate, xp and yp converged faster but did not reach the optimal solution because fluctuations keep occuring around the optimal solution but can not reach it due to the much bigger step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c898d0",
   "metadata": {},
   "source": [
    "## Trial 5\n",
    "**Trying a much smaller DELTA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23bcd340",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_p_final, y_p_final, x_p_list, y_p_list = optimize_return_parameters_list(5, 5, 0.001, 0.0001, 3000)\n",
    "\n",
    "print(f\"The final xp value: {x_p_final} and the final yp value: {y_p_final}\")\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "xp_ax = fig.add_subplot(1, 2, 1)\n",
    "yp_ax = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "xp_ax.plot(x_p_list)\n",
    "yp_ax.plot(y_p_list)\n",
    "\n",
    "xp_ax.set_title('Xp values with iterations')\n",
    "yp_ax.set_title('Yp values with iterations')\n",
    "\n",
    "xp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "xp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "yp_ax.yaxis.set_ticks([0.2*i for i in range(60)])\n",
    "yp_ax.set_ylim(bottom = 0, top = 6)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24515016",
   "metadata": {},
   "source": [
    "### Comment\n",
    "Using a very small DELTA, the step with which xp and yp are updated is so small that we need a very very large number of EPOCHS in order to reach the optimum values of xp and yp. We might get a more accurate estimation when we actually come near the optimum value, but it would take too many computations just to get there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
